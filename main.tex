\documentclass[sigconf,review,anonymous]{article}
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
%\usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
     %\usepackage[nonatbib]{neurips_2020}
\usepackage{multirow}
\usepackage[table,xcdraw]{xcolor}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks
% \usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{float} % here for H placement parameter
% \usepackage{multirow}
% \usepackage[normalem]{ulem}
% \useunder{\uline}{\ul}{}
% \usepackage{xcolor}
\usepackage[table,xcdraw]{xcolor}
\usepackage[obeyspaces]{url}
\usepackage{graphicx}
\usepackage{listings}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
% Reinsert missing \algbackskip
\def\algbackskip{\hskip-\ALG@thistlm}
\makeatother


\title{Realizing Literate Programming using Neural Machine Translation}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.
\author{%
  Anonymous Author(s)
}
% \author{%
  
%   Hung Phan \\
%   Department of Computer Science \\
%   Iowa State University\\
%   Ames, IA 50011 \\
%   hungphd@iastate.edu \\
% }

\begin{document}

\maketitle

\begin{abstract}
Literate Programming (LP) is a programming paradigm that unites natural language with code as one document, which helps the developer to explain the logic of some parts of the code both ways of representation. However, despite having advantages for code understanding,  LP hasn't been popularly applied in practice for two reasons. First, developers are required to specify the code for each natural language description manually which is a tedious and error-prone process. Secondly, supervised machine learning approaches for automatically retrieving code from Natural Language is expensive since it required a big dataset of the parallel corpus with NL and Programming Language. In this paper, we provide a tool InvocMap to realize LP to allow developers for writing the textual description of Method Invocations (MIs) inside code environment and get the correct MIs. Different from other code suggestion tools as AnyCode which was only considered natural language as input, we analyze the input from 2 sources: the NL description and its surrounding context. InvocMap proposes a semi-supervised approach by 3 modules. First, it uses unsupervised Neural Embedding to handle NL description of MIs to a list of possible method names. Second, Machine Translation models are trained from large scale code corpus to learn the structure of MIs given a list of method names and surrounding code context. Third, a program analysis step is proposed to assign local variables to structure of MIs to get the final code. InvocMap provides 2 modes of input for describing MIs for developers: from method names directly and from natural language description. By evaluation with training data from 1000 Java high-quality projects, we got the accuracy as up to 90\% for MI suggestion from method names and over 60\% for MI suggestion from NL description, which is outperforming the prior work AnyCode and showing the potential of realizing LP which is specified for supporting NL descriptions of MIs.
\end{abstract}

\section{Introduction}
Literate Programming (LP), which was invented by Donald E. Knuth \cite{001}, is intended to support software developers by a convenient programming environment. The idea of LP is to construct a sample program by an alternative way. The construction of program by LP is considered as a process contained two observations. First, they can consider the program as a list of statements which is handled by a compiler in programming language. This observation is traditional and be familiar with developers. The second observation is to consider a programming task as a description in the form of natural language. Unlike the first observation, the second observation proposes a new way of program representation by literature. It helps the program not only runnable but also explanable in human natural language. An application of LP is the WEB system \cite{001}, which can output the program as natural description and programming language in Pascal by Tangle and Waive library. LP does not only provide advantages in better programming experiences, but also introduce a solution for education of how to programming, based on the appearance of documentation for each code snippets.
\\
Despite having many advantages, the LP program paradigm has not been used popularly since its appearance in 1984. Based on our knowledge, the most recent application which applied LP is provided by  Haghish et al \cite{005}, which provide support for visualizing LP in HTML format. The most well-known LP dataset is \cite{006}, which provides LP dataset of code which are in the form of combination between Natural Language (NL) and code. \cite{004} studies about the problems which 
prevent LP to be practical. First, the number of developers who can be good at programming and documenting their code are limited. In the other words, developers seems to be good only at the first observation than the second observation of LP. Secondly, all of LP system like \cite{006} require manually defining the source code related to each natural language description. The cost for manually representing the code by NL and programming language (PL) for every code snippets of large scale corpus is expensive. Thus, it is important to have a system that automatically deriving the code from NL description in a code environment, to make LP feasible.
\\
From our knowledge, there is no tools or research projects which work directly on generating code for natural language parts for support LP in Software Engineering (SE) and Machine Learning (ML). However, the problem of generating code from natural language (NL) is one of interesting research problem in SE. In these works, AnyCode \cite{007} provides a solution for synthesizing expression, mostly in the form of Method Invocations (MIs) by proposing the language model called Probabilistic Context Free Grammar (PCFG).

\section{Background}
\section{The \textit{InvocMap} Model}
\subsection{Problem Formulation}
\begin{figure}
   
        \center{\includegraphics[width=\linewidth]
        {images/InvocMapOverview.png}}
        \caption{Overview of InvocMap model}
        \label{figOverview} 
\end{figure}
\begin{figure}
        \center{\includegraphics[width=\linewidth]
        {images/MotivatingExample.png}}
        \caption{Motivating Example of InvocMap}
        \label{figMotivatingExample} 
\end{figure}
\subsection{Code and Natural Language tokenization}
\subsection{Neural Embedding based for core method name inference}
\input{algorithmCombinePrePostCode.tex}
\subsection{Structured AST generation}
\subsection{Assigning variables to Structured AST}
\subsection{Ranking translated candidates }
\section{Evaluation}
\subsection{Data Preparation}
\begin{table}[]
\centering
\begin{tabular}{|l|r|}
\hline
\multicolumn{1}{|c|}{\textbf{Item}}                & \multicolumn{1}{c|}{\textbf{Number}} \\ \hline
Java projects                                      & 1000                                 \\ \hline
Size of Neural Embedding (NE) corpus               & 1770000                              \\ \hline
Size of Machine Translation corpus                 & 800000                               \\ \hline
Size of extrinsic corpus for NE                    & 120                                  \\ \hline
Size of extrinsic corpus for NL to code evaluation & 100                                  \\ \hline
Number of developers conduct in study of Q1        & 2                                    \\ \hline
Number of code snippet with NL in Q1               & 40                                   \\ \hline
\end{tabular}
\end{table}
\subsection{Baseline Method}
\subsection{Q1. How developers need for code suggestion from Method Name and from Natural Language}

\begin{table}[]
\centering
\begin{tabular}{|l|r|r|r|}
\hline
\multicolumn{1}{|c|}{\textbf{Input}} & \multicolumn{1}{l|}{\textbf{Cannot}} & \multicolumn{1}{l|}{\textbf{SomeParts}} & \multicolumn{1}{l|}{\textbf{AllParts}} \\ \hline
Core Method Name                     & 10\%                                 & 35\%                                    & 55\%                                   \\ \hline
Natural Language                     & 40\%                                 & 20\%                                    & 40\%                                   \\ \hline
\end{tabular}
\end{table}

\subsection{Q2. Accuracy of Neural Embedding for suggesting core method names  from natural language and surrounding code}

\begin{table}[]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{} & \textbf{PreCode}          & \textbf{PostCode}         & \textbf{Combine}          \\ \hline
Acccuracy & \multicolumn{1}{r|}{76\%} & \multicolumn{1}{r|}{76\%} & \multicolumn{1}{r|}{93\%} \\ \hline
\end{tabular}
\end{table}

\subsection{Q3. Accuracy of Machine Translation models for inferring structured AST from core method names}

\begin{table}[]
\centering
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{\textbf{Types of Evaluation}} & \multicolumn{3}{c|}{\textbf{Cross Validation}}                                                                    & \multicolumn{3}{c|}{\textbf{Extrinsic evaluation}}                                                                \\ \hline
\multicolumn{1}{|c|}{\textbf{Metric}}              & \multicolumn{1}{c|}{\textbf{Precision}} & \multicolumn{1}{c|}{\textbf{Recall}} & \multicolumn{1}{c|}{\textbf{F1}} & \multicolumn{1}{c|}{\textbf{Precision}} & \multicolumn{1}{c|}{\textbf{Recall}} & \multicolumn{1}{c|}{\textbf{F1}} \\ \hline
Core Method Name (C-MN)                            & 70.43                                   & 75.89                                & 73.06                            & 62.54                                   & 75.8                                 & 68.53                            \\ \hline
C-MN and variables                                 & 84.04                                   & 78.98                                & 81.43                            & 86.01                                   & 81.16                                & 83.51                            \\ \hline
C-MN, variables and terms                          & 89.33                                   & 79.98                                & 84.4                             & 86.88                                   & 81.31                                & 84                               \\ \hline
\end{tabular}
\end{table}

\subsection{Q4. Accuracy of InvocMap model for inferring code for realizing Literate Programming}

\begin{table}[]
\centering
\begin{tabular}{|l|r|}
\hline
\multicolumn{1}{|c|}{\textbf{Approach}} & \multicolumn{1}{c|}{\textbf{Accuracy in Top 1}} \\ \hline
AnyCode                                 & 44\%                                            \\ \hline
InvocMap                                & 61.19\%                                         \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{|l|r|}
\hline
\multicolumn{1}{|c|}{\textbf{Top result}} & \multicolumn{1}{c|}{\textbf{Accuracy}} \\ \hline
Top-1                                     & 61.19\%                                \\ \hline
Top-2                                     & 64.94\%                                \\ \hline
Top-3                                     & 68.13\%                                \\ \hline
Top-4                                     & 69.04\%                                \\ \hline
Top-5                                     & 70.02\%                                \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{|l|r|}
\hline
\multicolumn{1}{|c|}{\textbf{Top result}} & \multicolumn{1}{c|}{\textbf{Num of exact-match}} \\ \hline
InvocMap Top-1                            & 31                                               \\ \hline
InvocMap Top-10                           & 37                                               \\ \hline
\end{tabular}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{ID}} & \multicolumn{1}{c|}{\textbf{Natural Language / Expected result / Translated result}}        \\ \hline
\multicolumn{1}{|r|}{33}          & return square root of minDelta for Math                                                     \\ \hline
\rowcolor[HTML]{DAE8FC} 
                                  & \cellcolor[HTML]{DAE8FC}                                                                    \\ \cline{1-1}
\rowcolor[HTML]{DAE8FC} 
                                  & \multirow{-2}{*}{\cellcolor[HTML]{DAE8FC}Math.sqrt(minDelta)}                               \\ \hline
\multicolumn{1}{|r|}{44}          & attempt to establish connection to given jdbcUrl DbUser DbPwd for DriverManager             \\ \hline
\rowcolor[HTML]{DAE8FC} 
                                  & \cellcolor[HTML]{DAE8FC}                                                                    \\ \cline{1-1}
\rowcolor[HTML]{DAE8FC} 
                                  & \multirow{-2}{*}{\cellcolor[HTML]{DAE8FC}DriverManager.getConnection(jdbcUrl,DbUser,DbPwd)} \\ \hline
\multicolumn{1}{|r|}{2}           & return whether there contains a mapping to key uCode in UnicodeTeX.getMap()                 \\ \hline
\rowcolor[HTML]{DAE8FC} 
                                  & \cellcolor[HTML]{DAE8FC}                                                                    \\ \cline{1-1}
\rowcolor[HTML]{DAE8FC} 
                                  & \multirow{-2}{*}{\cellcolor[HTML]{DAE8FC}UnicodeTeX.getMap().containsKey(uCode)}            \\ \hline
\multicolumn{1}{|r|}{80}          & return the minimum of lp.height and height                                                  \\ \hline
\rowcolor[HTML]{FFCCC9} 
                                  & Math.min(lp.height,height)                                                                  \\ \hline
\rowcolor[HTML]{FFCCC9} 
                                  & Math.min(height,lp.height)                                                                  \\ \hline
\multicolumn{1}{|r|}{20}          & format now.getTime() into String and append to dateFormatter for SimpleDateFormat           \\ \hline
\rowcolor[HTML]{FFCCC9} 
                                  & dateFormatter.format(now.getTime())                                                         \\ \hline
\rowcolor[HTML]{FFCCC9} 
                                  & dateFormatter.format(now.getTime()).toString()                                              \\ \hline
\multicolumn{1}{|r|}{68}          & return a color from default key "MenuItem.acceleratorForeground" for UIManager              \\ \hline
\rowcolor[HTML]{FFCCC9} 
                                  & UIManager.getColor("MenuItem.acceleratorForeground")                                        \\ \hline
\rowcolor[HTML]{FFCCC9} 
                                  & UIManager.put("MenuItem.acceleratorForeground",color)                                       \\ \hline
\end{tabular}
\end{table}

\section{Related Work}
\section{Conclusion and Future Work}


\bibliography{references}{}
%this may not be right style for nips
\bibliographystyle{plain}


\end{document}
