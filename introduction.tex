\section{Introduction}
Literate Programming (LP), which was introduced by Donald E. Knuth \cite{001}, is intended to support software developers by a convenient programming environment. The idea of LP is to construct a sample program by an alternative way. The construction of program by LP is considered as a process contained two observations. First, they can consider the program as a list of statements which is handled by a compiler in programming language. This observation is traditional and be familiar with developers. The second observation is to consider a programming task as a description in the form of a natural language. Unlike the first observation, the second observation proposes a new way of program representation by literature. It helps the program not only runable but also explainable in human natural language. An application of LP is the WEB system \cite{001}, which can output the program as natural description and Pascal programming language by Tangle and Waive library. LP does not only provide advantages in better programming experiences, but also introduces a solution for education of how to programming, based on the appearance of documentation for each code snippets.
%Literate Programming (LP), which was invented by Donald E. Knuth \cite{001}, is intended to support software developers by a convenient programming environment. The idea of LP is to construct a sample program by an alternative way. The construction of program by LP is considered as a process contained two observations. First, they can consider the program as a list of statements which is handled by a compiler in programming language. This observation is traditional and be familiar with developers. The second observation is to consider a programming task as a description in the form of natural language. Unlike the first observation, the second observation proposes a new way of program representation by literature. It helps the program not only runnable but also explanable in human natural language. An application of LP is the WEB system \cite{001}, which can output the program as natural description and programming language in Pascal by Tangle and Waive library. LP does not only provide advantages in better programming experiences, but also introduce a solution for education of how to programming, based on the appearance of documentation for each code snippets.
\\
Despite having many advantages, the LP program paradigm has not been used popularly since its appearance in 1984. To the best of our knowledge, the most recent application which applied LP is done by Haghish et al \cite{005}, which provides support for visualizing LP in HTML format. The most well-known LP dataset \cite{006} provides a dataset of code in the form of combination between Natural Language (NL) and source code. \cite{004} studies about the problems which prevent LP to be practical. First, the number of developers who can be good both at programming and documenting their code are limited. In the other words, developers seem to be good only at the first observation than the second observation. Second, all of LP systems like \cite{006} require manually defining the source code related to each natural language description. The cost for manually representing the code by NL and programming language (PL) for every code snippets of large scale corpus is expensive. Thus, it is important to have a system that automatically derives the code from NL description in a code environment, to make LP feasible.
%Despite having many advantages, the LP program paradigm has not been used popularly since its appearance in 1984. Based on our knowledge, the most recent application which applied LP is provided by  Haghish et al \cite{005}, which provide support for visualizing LP in HTML format. The most well-known LP dataset is \cite{006}, which provides LP dataset of code which are in the form of combination between Natural Language (NL) and code. \cite{004} studies about the problems which prevent LP to be practical. First, the number of developers who can be good at programming and documenting their code are limited. In the other words, developers seems to be good only at the first observation than the second observation of LP. Secondly, all of LP system like \cite{006} require manually defining the source code related to each natural language description. The cost for manually representing the code by NL and programming language (PL) for every code snippets of large scale corpus is expensive. Thus, it is important to have a system that automatically deriving the code from NL description in a code environment, to make LP feasible.
\\
To the best of our knowledge, there is no work directly on generating code for natural language parts to support LP in Software Engineering (SE) and Machine Learning (ML). However, the problem of generating code from natural language (NL) is considered generally as one of the interesting research problems in SE. In related works, AnyCode \cite{007} provides a solution for synthesizing expression, mostly in the form of Method Invocations (MIs) by proposing the language model called Probabilistic Context Free Grammar (PCFG). Other works applied and optimized Machine Translation (MT) by providing supervised approaches for inferring code from natural description and vice versa. \cite{008} provides a tree based code generation which can be integrated in Recurrent Neural Network (RNN) for Python. \cite{009} applied Statistical Machine Translation (SMT) model for learning pseudo code from actual code for code summarization. This trend of research requires manually annotated data for supervised learning, which is expensive when applied in other types of NL. Although NL description and code can be extracted from large scale code repository, parallel corpus extracted by this way is usually erroneous and noisy.  Barone  et al. \cite{010} conduct a Python corpus by automatically extracting documentation and implementation of the same Python methods. By the experiment, they show that applying Machine Translation models to this corpus is challenging since the accuracy on both SMT and Neural Machine Translation (NMT) are low.
%From our knowledge, there is no tools or research projects which work directly on generating code for natural language parts for support LP in Software Engineering (SE) and Machine Learning (ML). However, the problem of generating code from natural language (NL) is one of interesting research problem in SE. In these works, AnyCode \cite{007} provides a solution for synthesizing expression, mostly in the form of Method Invocations (MIs) by proposing the language model called Probabilistic Context Free Grammar (PCFG). Other works applied and optimized Machine Translation (MT) by providing supervised approaches for inferring code from natural description and vice versa. \cite{008} provides a tree based code generation which can be integrated in Recurrent Neural Network (RNN) for Python. \cite{009} applied Statistical Machine Translation (SMT) model for learning pseudo code from actual code for code summarixation. This trend of research require manually annotated data for supervised learning, which is expensive when applied in other types of NL. Although NL description and code can be extracted from large scale code repository, parallel corpus extracted by this way is usually erroneous and contain noise.  Barone  et al. \cite{010} conduct a Python corpus by automatically extracting documentation and implementation of the same Python methods. By the experiment, they show that applying Machine Translation models to this corpus is challenging since the accuracy on both SMT and Neural Machine Translation (NMT) are low.
\\
All of existing works \cite{007,008,009,010} on generating code from natural language as input do not consider LP and were not designed to support LP. They treat solely the natural language as the entire input and provide the generated code as output, without considering a combination of code and NL text and neglecting the information from the surrounding code. \cite{010} considered the input as natural description of functions in Java Documentation (JavaDoc) for each functions of Python. AnyCode (\cite{007}) provides a solution for getting MIs by standalone NL queries instead of NL elements inside the code. In the other words, the expressions generated from AnyCode is consistent regardless the surrounding code and context.
%All of current works on generating code from natural language input like \cite{007,008,009,010} were not designed to support LP. They treat the natural language as the entire input and provide the output as generated code, without considering the information from surrounding code. \cite{010} considered the input as natural description of functions in Java Documentation (JavaDoc) for each functions of Python. AnyCode (\cite{007}) provides a solution for getting MIs by NL queries instead of NL element inside the code. In the other words, the output of expressions generated from AnyCode is consistent regardless the surrounding code.
\\
This paper is an attempt to realize Literate Programming by proposing InvocMap, a tool that helps developers to define natural language description of method invocations at any locations inside the code environment and automatically suggests MIs for all NL descriptions. Unlike prior works, we consider the input as an LP code snippet and consider code as a combination of sequence of code elements and natural language elements (NL-E). We provide the output as code snippet that all of NL-E were transformed to MIs. To achieve the solution, we provide a semi-supervised approach which combines three techniques: neural embedding to get method names from surrounding context and natural language elements; machine translation to get the parsed tree of MIs; program analysis techniques to analyze the surrounding context and instrument information to tree representation for getting the final code. In summary, We provide the following contributions:
\begin{itemize}
	\item Another viewpoint for considering natural language elements with information of surrounding code before and after it. 
	\item An approach for automatically generating method names based on all NL description and code information. 
	\item A Machine Translation model which converts text to tree data structure of Method Invocations.
	\item A code suggestion tool to realize LP by two modes: we allow developers to input method names and get method invocations, or  write free-form NL elements and get the suggested code.
\end{itemize}
%In this paper, we want to realizing Literate Programming by providing InvocMap, a tool that helps developers to define natural language description of method invocations at any locations inside the code environment and automatically suggesting MIs for all descriptions. Unlike prior works, we consider the input as a LP code snippet, which considers code as the combination of sequence of code elements and natural language elements (NL-E). We provide the output as code snippet that all of NL-E were transformed to MIs. To achieve the solution, we provide a semi-supervised approach which combines three techniques: neural embedding to get method names from surrounding context and natural language element; machine translation to get the parsed tree of MIs; Program Analysis to analyze the surrounding context to instrument information to tree to get the final code. We provide following contributions:
%\begin{itemize}
%	\item Provided another viewpoint for considering natural language element with information of code before and after it. 
%	\item Implemented an approach for automatically generating possible method names based on all NL and code information. 
%	\item Built a Machine Translation model which converted from text to tree data structure of Method Invocation.
%	\item Provided a code suggestion tool InvocMap to realizing LP by 2 modes. In the first mode, we allow developers to input method names and other information to get the method invocations. In the second mode, developers can write free form NL elements and get suggested code as list of MIs which the highest ranking suggested option as the most relevant code suggested by InvocMap.
%\end{itemize}
